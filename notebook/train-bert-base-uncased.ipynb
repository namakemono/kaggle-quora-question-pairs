{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"train-bert-base-uncased","provenance":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"cells":[{"cell_type":"markdown","metadata":{"id":"vQj8Rz1yTMs9"},"source":["## References\n","\n","- https://github.com/huggingface/transformers/blob/5f2a3d721c514cb160c74d2f2df6b729c2f99b2d/examples/text-classification/run_tf_text_classification.py\n","\n","- [Jigsaw TPU: DistilBERT with Huggingface and Keras](https://www.kaggle.com/xhlulu/jigsaw-tpu-distilbert-with-huggingface-and-keras)\n","\n","- https://huggingface.co/transformers/master/training.html"]},{"cell_type":"code","metadata":{"id":"Y-ZZuyEHTMtB","executionInfo":{"status":"ok","timestamp":1616883891575,"user_tz":-540,"elapsed":1157,"user":{"displayName":"西森雅峰","photoUrl":"","userId":"14712724062217715309"}}},"source":["import os\n","import sys"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6g508Aqv4w7D","executionInfo":{"status":"ok","timestamp":1616883892066,"user_tz":-540,"elapsed":1642,"user":{"displayName":"西森雅峰","photoUrl":"","userId":"14712724062217715309"}},"outputId":"7996ce5b-6a0f-4678-d4cf-48d32815ca17"},"source":["if \"google.colab\" in sys.modules:\n","    from google.colab import drive\n","    drive.mount('/content/drive')\n","    %cd /content/drive/MyDrive/kaggle/kaggle-quora-question-pairs/notebook"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/MyDrive/kaggle/kaggle-quora-question-pairs/notebook\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"c30I6d02n7uC","executionInfo":{"status":"ok","timestamp":1616883896451,"user_tz":-540,"elapsed":6020,"user":{"displayName":"西森雅峰","photoUrl":"","userId":"14712724062217715309"}}},"source":["!pip install transformers -q\n","!pip install datasets -q"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"a2QX0XLQhe4A","executionInfo":{"status":"ok","timestamp":1616883898858,"user_tz":-540,"elapsed":8422,"user":{"displayName":"西森雅峰","photoUrl":"","userId":"14712724062217715309"}}},"source":["import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","from sklearn.model_selection import KFold\n","from sklearn.metrics import accuracy_score\n","import transformers\n","import datasets\n","from transformers import (\n","    AutoTokenizer,\n","    TFAutoModelForSequenceClassification,\n",")"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"E1p24QGboHUZ","executionInfo":{"status":"ok","timestamp":1616883898859,"user_tz":-540,"elapsed":8420,"user":{"displayName":"西森雅峰","photoUrl":"","userId":"14712724062217715309"}}},"source":["os.makedirs(\"../output\", exist_ok=True)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"OfusCWHwhhbR","executionInfo":{"status":"ok","timestamp":1616883898860,"user_tz":-540,"elapsed":8417,"user":{"displayName":"西森雅峰","photoUrl":"","userId":"14712724062217715309"}}},"source":["class Config:\n","    def __init__(self):\n","        self.debug = False\n","        self.output_directory = \"../output\"\n","        self.train_filepath = \"../input/quora-question-pairs/train.csv\"\n","        self.test_filepath = \"../input/quora-question-pairs/test.csv\"\n","        self.model_name = \"bert-base-uncased\"\n","        self.max_seq_length = 128\n","        self.batch_size = 32\n","        self.epochs = 3\n","        self.num_splits = 3\n","        self.name = \"_\".join([\n","            self.model_name,\n","            \"seqlen-%d\" % self.max_seq_length,\n","            \"debug\" if self.debug else \"prod\"\n","        ])\n","        self.weights_filepath_list = [f\"{self.output_directory}/{self.name}-{kfold_index}.h5\" for kfold_index in range(self.num_splits)]\n","        \n","config = Config()"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"PRpkzubtnn8r","executionInfo":{"status":"ok","timestamp":1616883899939,"user_tz":-540,"elapsed":9493,"user":{"displayName":"西森雅峰","photoUrl":"","userId":"14712724062217715309"}}},"source":["train_df = pd.read_csv(config.train_filepath)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"iPXEud95XNY3","executionInfo":{"status":"ok","timestamp":1616883899943,"user_tz":-540,"elapsed":9494,"user":{"displayName":"西森雅峰","photoUrl":"","userId":"14712724062217715309"}}},"source":["def preprocess(df):\n","    df.fillna(\"\", inplace=True)\n","preprocess(train_df)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"1RmzKPQelGSe","executionInfo":{"status":"ok","timestamp":1616883899944,"user_tz":-540,"elapsed":9492,"user":{"displayName":"西森雅峰","photoUrl":"","userId":"14712724062217715309"}}},"source":["if config.debug:\n","    train_df = train_df.sample(300)"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"9cVWJgRk5V-l","executionInfo":{"status":"ok","timestamp":1616883899944,"user_tz":-540,"elapsed":9488,"user":{"displayName":"西森雅峰","photoUrl":"","userId":"14712724062217715309"}},"outputId":"7da44318-a8a5-4551-e530-4b6398eee44d"},"source":["train_df.head()"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>qid1</th>\n","      <th>qid2</th>\n","      <th>question1</th>\n","      <th>question2</th>\n","      <th>is_duplicate</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>What is the step by step guide to invest in sh...</td>\n","      <td>What is the step by step guide to invest in sh...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n","      <td>What would happen if the Indian government sto...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>5</td>\n","      <td>6</td>\n","      <td>How can I increase the speed of my internet co...</td>\n","      <td>How can Internet speed be increased by hacking...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>7</td>\n","      <td>8</td>\n","      <td>Why am I mentally very lonely? How can I solve...</td>\n","      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>9</td>\n","      <td>10</td>\n","      <td>Which one dissolve in water quikly sugar, salt...</td>\n","      <td>Which fish would survive in salt water?</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   id  qid1  ...                                          question2 is_duplicate\n","0   0     1  ...  What is the step by step guide to invest in sh...            0\n","1   1     3  ...  What would happen if the Indian government sto...            0\n","2   2     5  ...  How can Internet speed be increased by hacking...            0\n","3   3     7  ...  Find the remainder when [math]23^{24}[/math] i...            0\n","4   4     9  ...            Which fish would survive in salt water?            0\n","\n","[5 rows x 6 columns]"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"1j5P_9MdTMtF","executionInfo":{"status":"ok","timestamp":1616883901662,"user_tz":-540,"elapsed":11199,"user":{"displayName":"西森雅峰","photoUrl":"","userId":"14712724062217715309"}}},"source":["tokenizer = AutoTokenizer.from_pretrained(config.model_name, use_fast=True)"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"_-VcvYA4imMT","executionInfo":{"status":"ok","timestamp":1616883901663,"user_tz":-540,"elapsed":11195,"user":{"displayName":"西森雅峰","photoUrl":"","userId":"14712724062217715309"}}},"source":["# cf. https://www.kaggle.com/nandanapoorv/entity-recognition-with-tf-keras-and-huggingface\n","# cf. https://www.kaggle.com/cdeotte/tensorflow-roberta-0-705\n","def build_model():\n","    x_input_ids = tf.keras.Input(shape=(config.max_seq_length, ), dtype=tf.int32)\n","    x_attention_mask = tf.keras.Input(shape=(config.max_seq_length, ), dtype=tf.int32)\n","    x_token_type_ids = tf.keras.Input(shape=(config.max_seq_length, ), dtype=tf.int32)\n","    bert_model = transformers.TFBertModel.from_pretrained(config.model_name)\n","    outputs = bert_model(\n","        input_ids=x_input_ids,\n","        attention_mask=x_attention_mask,\n","        token_type_ids=x_token_type_ids\n","    )\n","    prediction = tf.keras.layers.Dense(1, activation=\"sigmoid\")(outputs.pooler_output)\n","    model = tf.keras.Model(\n","        inputs=[x_input_ids, x_attention_mask, x_token_type_ids],\n","        outputs=[prediction]\n","    )\n","    model.compile(\n","        optimizer=tf.keras.optimizers.Adam(learning_rate=3e-5),\n","        loss=\"binary_crossentropy\"\n","    )\n","    return model"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"SoEJgCAFimMU","executionInfo":{"status":"ok","timestamp":1616883901664,"user_tz":-540,"elapsed":11193,"user":{"displayName":"西森雅峰","photoUrl":"","userId":"14712724062217715309"}}},"source":["def to_dataset(df):\n","    input_shape = (len(df), config.max_seq_length)\n","    input_ids = np.zeros(input_shape, dtype=np.int32)\n","    attention_mask = np.zeros(input_shape, dtype=np.int32)\n","    token_type_ids = np.zeros(input_shape, dtype=np.int32)\n","    tokens = df.apply(lambda example: tokenizer(\n","        example[\"question1\"],\n","        example[\"question2\"],\n","        truncation=True,\n","        max_length=config.max_seq_length,\n","        padding=\"max_length\"\n","    ), axis=1)\n","    for i, token in enumerate(tokens):\n","        input_ids[i] = token[\"input_ids\"]\n","        attention_mask[i] = token[\"attention_mask\"]\n","        token_type_ids[i] = token[\"token_type_ids\"]\n","    x = (input_ids, attention_mask, token_type_ids)\n","    y = df[\"is_duplicate\"].values\n","    return x, y"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UcThVGKSjGo2","executionInfo":{"status":"ok","timestamp":1616927082567,"user_tz":-540,"elapsed":43192086,"user":{"displayName":"西森雅峰","photoUrl":"","userId":"14712724062217715309"}},"outputId":"910dc17a-db5e-4403-ed36-d8130ce11e14"},"source":["kf = KFold(n_splits=3, shuffle=True, random_state=777)\n","oof = np.zeros(len(train_df))\n","for kfold_index, (train_index, valid_index) in enumerate(kf.split(train_df)):\n","    weights_filepath = config.weights_filepath_list[kfold_index]\n","    callbacks = [\n","        tf.keras.callbacks.ModelCheckpoint(\n","            weights_filepath,\n","            monitor=\"val_loss\",\n","            verbose=1,\n","            save_best_only=True,\n","            save_weights_only=True\n","        )\n","    ]\n","    print(\"Convert to train dataset.\")\n","    x_train, y_train = to_dataset(train_df.iloc[train_index])\n","    x_valid, y_valid = to_dataset(train_df.iloc[valid_index])\n","    print(\"Buiild model\")\n","    model = build_model()\n","    if kfold_index == 0:\n","        print(model.summary())\n","    print(\"Start train\")\n","    model.fit(\n","        x_train, y_train,\n","        validation_data=(x_valid, y_valid),\n","        callbacks=callbacks,\n","        epochs=config.epochs,\n","        batch_size=config.batch_size\n","    )\n","    print(\"Start predict\")\n","    model.load_weights(weights_filepath)\n","    oof[valid_index] = model.predict(x_valid).flatten()"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Convert to train dataset.\n","Buiild model\n"],"name":"stdout"},{"output_type":"stream","text":["Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f6271a28050>> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f6271a28050>> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function wrap at 0x7f629d2b7c20> and will run it as-is.\n","Cause: while/else statement not yet supported\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING: AutoGraph could not transform <function wrap at 0x7f629d2b7c20> and will run it as-is.\n","Cause: while/else statement not yet supported\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","Model: \"model\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 128)]        0                                            \n","__________________________________________________________________________________________________\n","input_2 (InputLayer)            [(None, 128)]        0                                            \n","__________________________________________________________________________________________________\n","input_3 (InputLayer)            [(None, 128)]        0                                            \n","__________________________________________________________________________________________________\n","tf_bert_model (TFBertModel)     TFBaseModelOutputWit 109482240   input_1[0][0]                    \n","                                                                 input_2[0][0]                    \n","                                                                 input_3[0][0]                    \n","__________________________________________________________________________________________________\n","dense (Dense)                   (None, 1)            769         tf_bert_model[0][1]              \n","==================================================================================================\n","Total params: 109,483,009\n","Trainable params: 109,483,009\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","None\n","Start train\n","Epoch 1/3\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","8423/8423 [==============================] - ETA: 0s - loss: 0.3504WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","8423/8423 [==============================] - 4529s 536ms/step - loss: 0.3504 - val_loss: 0.2523\n","\n","Epoch 00001: val_loss improved from inf to 0.25227, saving model to ../output/bert-base-uncased_seqlen-128_prod-0.h5\n","Epoch 2/3\n","8423/8423 [==============================] - 4511s 536ms/step - loss: 0.1952 - val_loss: 0.2466\n","\n","Epoch 00002: val_loss improved from 0.25227 to 0.24660, saving model to ../output/bert-base-uncased_seqlen-128_prod-0.h5\n","Epoch 3/3\n","8423/8423 [==============================] - 4515s 536ms/step - loss: 0.1246 - val_loss: 0.2840\n","\n","Epoch 00003: val_loss did not improve from 0.24660\n","Start predict\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","Convert to train dataset.\n","Buiild model\n"],"name":"stdout"},{"output_type":"stream","text":["Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","Start train\n","Epoch 1/3\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","8423/8423 [==============================] - ETA: 0s - loss: 0.3452WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","8423/8423 [==============================] - 4531s 536ms/step - loss: 0.3452 - val_loss: 0.2583\n","\n","Epoch 00001: val_loss improved from inf to 0.25829, saving model to ../output/bert-base-uncased_seqlen-128_prod-1.h5\n","Epoch 2/3\n","8423/8423 [==============================] - 4521s 537ms/step - loss: 0.1946 - val_loss: 0.2426\n","\n","Epoch 00002: val_loss improved from 0.25829 to 0.24263, saving model to ../output/bert-base-uncased_seqlen-128_prod-1.h5\n","Epoch 3/3\n","8423/8423 [==============================] - 4535s 538ms/step - loss: 0.1248 - val_loss: 0.2781\n","\n","Epoch 00003: val_loss did not improve from 0.24263\n","Start predict\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","Convert to train dataset.\n","Buiild model\n"],"name":"stdout"},{"output_type":"stream","text":["Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","Start train\n","Epoch 1/3\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","8423/8423 [==============================] - ETA: 0s - loss: 0.3467WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","8423/8423 [==============================] - 4554s 539ms/step - loss: 0.3467 - val_loss: 0.2450\n","\n","Epoch 00001: val_loss improved from inf to 0.24502, saving model to ../output/bert-base-uncased_seqlen-128_prod-2.h5\n","Epoch 2/3\n","8423/8423 [==============================] - 4539s 539ms/step - loss: 0.1952 - val_loss: 0.2429\n","\n","Epoch 00002: val_loss improved from 0.24502 to 0.24287, saving model to ../output/bert-base-uncased_seqlen-128_prod-2.h5\n","Epoch 3/3\n","8423/8423 [==============================] - 4538s 539ms/step - loss: 0.1260 - val_loss: 0.2799\n","\n","Epoch 00003: val_loss did not improve from 0.24287\n","Start predict\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BGu_mEyDjGev","executionInfo":{"status":"ok","timestamp":1616928381208,"user_tz":-540,"elapsed":880,"user":{"displayName":"西森雅峰","photoUrl":"","userId":"14712724062217715309"}},"outputId":"dd65858d-0fa4-49cf-b425-a4926bd35d20"},"source":["y = train_df[\"is_duplicate\"].values\n","print(\"positive ratio: %.4f\" % np.mean(y))\n","print(\"acc: %.4f\" % accuracy_score(y, oof > 0.5))"],"execution_count":16,"outputs":[{"output_type":"stream","text":["positive ratio: 0.3692\n","acc: 0.9006\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ybTDvXD3__d6","executionInfo":{"status":"aborted","timestamp":1616927083195,"user_tz":-540,"elapsed":43192706,"user":{"displayName":"西森雅峰","photoUrl":"","userId":"14712724062217715309"}}},"source":[""],"execution_count":null,"outputs":[]}]}