{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"train-roberta-base.ipynb","provenance":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"cells":[{"cell_type":"markdown","metadata":{"id":"vQj8Rz1yTMs9"},"source":["## References\n","\n","- https://github.com/huggingface/transformers/blob/5f2a3d721c514cb160c74d2f2df6b729c2f99b2d/examples/text-classification/run_tf_text_classification.py\n","\n","- [Jigsaw TPU: DistilBERT with Huggingface and Keras](https://www.kaggle.com/xhlulu/jigsaw-tpu-distilbert-with-huggingface-and-keras)\n","\n","- https://huggingface.co/transformers/master/training.html"]},{"cell_type":"code","metadata":{"id":"Y-ZZuyEHTMtB","executionInfo":{"status":"ok","timestamp":1616884518462,"user_tz":-540,"elapsed":780,"user":{"displayName":"西森雅峰","photoUrl":"","userId":"14712724062217715309"}}},"source":["import os\n","import sys"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6g508Aqv4w7D","executionInfo":{"status":"ok","timestamp":1616884518751,"user_tz":-540,"elapsed":1063,"user":{"displayName":"西森雅峰","photoUrl":"","userId":"14712724062217715309"}},"outputId":"2b8e3328-cd29-4370-8a9a-5cecf5a51f37"},"source":["if \"google.colab\" in sys.modules:\n","    from google.colab import drive\n","    drive.mount('/content/drive')\n","    %cd /content/drive/MyDrive/kaggle/kaggle-quora-question-pairs/notebook"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/MyDrive/kaggle/kaggle-quora-question-pairs/notebook\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"c30I6d02n7uC","executionInfo":{"status":"ok","timestamp":1616884526270,"user_tz":-540,"elapsed":8577,"user":{"displayName":"西森雅峰","photoUrl":"","userId":"14712724062217715309"}}},"source":["!pip install transformers -q\n","!pip install datasets -q\n","!pip install wandb -q"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"a2QX0XLQhe4A","executionInfo":{"status":"ok","timestamp":1616884528560,"user_tz":-540,"elapsed":10864,"user":{"displayName":"西森雅峰","photoUrl":"","userId":"14712724062217715309"}}},"source":["import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","from sklearn.model_selection import KFold\n","import transformers\n","import datasets\n","from sklearn.metrics import accuracy_score\n","from transformers import (\n","    AutoTokenizer,\n","    TFAutoModelForSequenceClassification,\n",")"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"OfusCWHwhhbR","executionInfo":{"status":"ok","timestamp":1616884528568,"user_tz":-540,"elapsed":10868,"user":{"displayName":"西森雅峰","photoUrl":"","userId":"14712724062217715309"}}},"source":["class Config:\n","    def __init__(self):\n","        self.debug = False\n","        self.output_directory = \"../output\"\n","        self.train_filepath = \"../input/quora-question-pairs/train.csv\"\n","        self.test_filepath = \"../input/quora-question-pairs/test.csv\"\n","        self.model_name = \"roberta-base\"\n","        self.max_seq_length = 128\n","        self.batch_size = 32\n","        self.epochs = 3\n","        self.num_splits = 3\n","        self.name = \"_\".join([\n","            self.model_name,\n","            \"seqlen-%d\" % self.max_seq_length,\n","            \"debug\" if self.debug else \"prod\"\n","        ])\n","        self.weights_filepath_list = [f\"{self.output_directory}/{self.name}-{kfold_index}.h5\" for kfold_index in range(self.num_splits)]\n","        \n","config = Config()"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"uxj9BVsEocm1","executionInfo":{"status":"ok","timestamp":1616884528570,"user_tz":-540,"elapsed":10866,"user":{"displayName":"西森雅峰","photoUrl":"","userId":"14712724062217715309"}}},"source":["os.makedirs(config.output_directory, exist_ok=True)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"PRpkzubtnn8r","executionInfo":{"status":"ok","timestamp":1616884529451,"user_tz":-540,"elapsed":11744,"user":{"displayName":"西森雅峰","photoUrl":"","userId":"14712724062217715309"}}},"source":["train_df = pd.read_csv(config.train_filepath)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"iPXEud95XNY3","executionInfo":{"status":"ok","timestamp":1616884529459,"user_tz":-540,"elapsed":11749,"user":{"displayName":"西森雅峰","photoUrl":"","userId":"14712724062217715309"}}},"source":["def preprocess(df):\n","    df.fillna(\"\", inplace=True)\n","preprocess(train_df)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"1RmzKPQelGSe","executionInfo":{"status":"ok","timestamp":1616884529461,"user_tz":-540,"elapsed":11749,"user":{"displayName":"西森雅峰","photoUrl":"","userId":"14712724062217715309"}}},"source":["if config.debug:\n","    train_df = train_df.sample(300)"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"9cVWJgRk5V-l","executionInfo":{"status":"ok","timestamp":1616884529461,"user_tz":-540,"elapsed":11745,"user":{"displayName":"西森雅峰","photoUrl":"","userId":"14712724062217715309"}},"outputId":"29174ad2-b020-46a6-d3b9-d02240b1ff96"},"source":["train_df.head()"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>qid1</th>\n","      <th>qid2</th>\n","      <th>question1</th>\n","      <th>question2</th>\n","      <th>is_duplicate</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>What is the step by step guide to invest in sh...</td>\n","      <td>What is the step by step guide to invest in sh...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n","      <td>What would happen if the Indian government sto...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>5</td>\n","      <td>6</td>\n","      <td>How can I increase the speed of my internet co...</td>\n","      <td>How can Internet speed be increased by hacking...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>7</td>\n","      <td>8</td>\n","      <td>Why am I mentally very lonely? How can I solve...</td>\n","      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>9</td>\n","      <td>10</td>\n","      <td>Which one dissolve in water quikly sugar, salt...</td>\n","      <td>Which fish would survive in salt water?</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   id  qid1  ...                                          question2 is_duplicate\n","0   0     1  ...  What is the step by step guide to invest in sh...            0\n","1   1     3  ...  What would happen if the Indian government sto...            0\n","2   2     5  ...  How can Internet speed be increased by hacking...            0\n","3   3     7  ...  Find the remainder when [math]23^{24}[/math] i...            0\n","4   4     9  ...            Which fish would survive in salt water?            0\n","\n","[5 rows x 6 columns]"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"1j5P_9MdTMtF","executionInfo":{"status":"ok","timestamp":1616884531546,"user_tz":-540,"elapsed":13825,"user":{"displayName":"西森雅峰","photoUrl":"","userId":"14712724062217715309"}}},"source":["tokenizer = AutoTokenizer.from_pretrained(config.model_name, use_fast=True)"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"_-VcvYA4imMT","executionInfo":{"status":"ok","timestamp":1616884531550,"user_tz":-540,"elapsed":13826,"user":{"displayName":"西森雅峰","photoUrl":"","userId":"14712724062217715309"}}},"source":["# cf. https://www.kaggle.com/nandanapoorv/entity-recognition-with-tf-keras-and-huggingface\n","# cf. https://www.kaggle.com/cdeotte/tensorflow-roberta-0-705\n","def build_model():\n","    x_input_ids = tf.keras.Input(shape=(config.max_seq_length, ), dtype=tf.int32)\n","    x_attention_mask = tf.keras.Input(shape=(config.max_seq_length, ), dtype=tf.int32)\n","    x_token_type_ids = tf.keras.Input(shape=(config.max_seq_length, ), dtype=tf.int32)\n","    bert_model = transformers.TFAutoModel.from_pretrained(config.model_name)\n","    outputs = bert_model(\n","        input_ids=x_input_ids,\n","        attention_mask=x_attention_mask,\n","        token_type_ids=x_token_type_ids\n","    )\n","    prediction = tf.keras.layers.Dense(1, activation=\"sigmoid\")(outputs.pooler_output)\n","    model = tf.keras.Model(\n","        inputs=[x_input_ids, x_attention_mask, x_token_type_ids],\n","        outputs=[prediction]\n","    )\n","    model.compile(\n","        optimizer=tf.keras.optimizers.Adam(learning_rate=3e-5),\n","        loss=\"binary_crossentropy\"\n","    )\n","    return model"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"SoEJgCAFimMU","executionInfo":{"status":"ok","timestamp":1616884531551,"user_tz":-540,"elapsed":13824,"user":{"displayName":"西森雅峰","photoUrl":"","userId":"14712724062217715309"}}},"source":["def to_dataset(df):\n","    input_shape = (len(df), config.max_seq_length)\n","    input_ids = np.zeros(input_shape, dtype=np.int32)\n","    attention_mask = np.zeros(input_shape, dtype=np.int32)\n","    token_type_ids = np.zeros(input_shape, dtype=np.int32)\n","    tokens = df.apply(lambda example: tokenizer(\n","        example[\"question1\"],\n","        example[\"question2\"],\n","        truncation=True,\n","        max_length=config.max_seq_length,\n","        padding=\"max_length\"\n","    ), axis=1)\n","    for i, token in enumerate(tokens):\n","        input_ids[i] = token[\"input_ids\"]\n","        attention_mask[i] = token[\"attention_mask\"]\n","        if \"token_type_ids\" in token:\n","            token_type_ids[i] = token[\"token_type_ids\"]\n","    x = (input_ids, attention_mask, token_type_ids)\n","    y = df[\"is_duplicate\"].values\n","    return x, y"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UcThVGKSjGo2","executionInfo":{"status":"ok","timestamp":1616910335713,"user_tz":-540,"elapsed":25777699,"user":{"displayName":"西森雅峰","photoUrl":"","userId":"14712724062217715309"}},"outputId":"cfff10bf-4130-42c5-865a-ba9d3f8408b1"},"source":["kf = KFold(n_splits=config.num_splits, shuffle=True, random_state=777)\n","oof = np.zeros(len(train_df))\n","for kfold_index, (train_index, valid_index) in enumerate(kf.split(train_df)):\n","    weights_filepath = f\"../output/{config.model_name}-{kfold_index}.h5\"\n","    callbacks = [\n","        tf.keras.callbacks.ModelCheckpoint(\n","            weights_filepath,\n","            monitor=\"val_loss\",\n","            verbose=1,\n","            save_best_only=True,\n","            save_weights_only=True\n","        )\n","    ]\n","    print(\"Convert to train dataset.\")\n","    x_train, y_train = to_dataset(train_df.iloc[train_index])\n","    x_valid, y_valid = to_dataset(train_df.iloc[valid_index])\n","    print(\"Buiild model\")\n","    model = build_model()\n","    if kfold_index == 0:\n","        print(model.summary())\n","    print(\"Start train\")\n","    model.fit(\n","        x_train, y_train,\n","        validation_data=(x_valid, y_valid),\n","        callbacks=callbacks,\n","        epochs=config.epochs,\n","        batch_size=config.batch_size\n","    )\n","    print(\"Start predict\")\n","    model.load_weights(weights_filepath)\n","    oof[valid_index] = model.predict(x_valid).flatten()"],"execution_count":16,"outputs":[{"output_type":"stream","text":["Convert to train dataset.\n","Buiild model\n"],"name":"stdout"},{"output_type":"stream","text":["Some layers from the model checkpoint at roberta-base were not used when initializing TFRobertaModel: ['lm_head']\n","- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-base.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f69ab4a51a0>> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f69ab4a51a0>> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function wrap at 0x7f69d6d30c20> and will run it as-is.\n","Cause: while/else statement not yet supported\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING: AutoGraph could not transform <function wrap at 0x7f69d6d30c20> and will run it as-is.\n","Cause: while/else statement not yet supported\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","Model: \"model\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 128)]        0                                            \n","__________________________________________________________________________________________________\n","input_2 (InputLayer)            [(None, 128)]        0                                            \n","__________________________________________________________________________________________________\n","input_3 (InputLayer)            [(None, 128)]        0                                            \n","__________________________________________________________________________________________________\n","tf_roberta_model (TFRobertaMode TFBaseModelOutputWit 124645632   input_1[0][0]                    \n","                                                                 input_2[0][0]                    \n","                                                                 input_3[0][0]                    \n","__________________________________________________________________________________________________\n","dense (Dense)                   (None, 1)            769         tf_roberta_model[0][1]           \n","==================================================================================================\n","Total params: 124,646,401\n","Trainable params: 124,646,401\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","None\n","Start train\n","Epoch 1/3\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","8423/8423 [==============================] - ETA: 0s - loss: 0.3549WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","8423/8423 [==============================] - 2690s 318ms/step - loss: 0.3549 - val_loss: 0.2605\n","\n","Epoch 00001: val_loss improved from inf to 0.26055, saving model to ../output/roberta-base-0.h5\n","Epoch 2/3\n","8423/8423 [==============================] - 2680s 318ms/step - loss: 0.2297 - val_loss: 0.2398\n","\n","Epoch 00002: val_loss improved from 0.26055 to 0.23978, saving model to ../output/roberta-base-0.h5\n","Epoch 3/3\n","8423/8423 [==============================] - 2681s 318ms/step - loss: 0.1783 - val_loss: 0.2552\n","\n","Epoch 00003: val_loss did not improve from 0.23978\n","Start predict\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","Convert to train dataset.\n","Buiild model\n"],"name":"stdout"},{"output_type":"stream","text":["Some layers from the model checkpoint at roberta-base were not used when initializing TFRobertaModel: ['lm_head']\n","- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-base.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","Start train\n","Epoch 1/3\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","8423/8423 [==============================] - ETA: 0s - loss: 0.3510WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","8423/8423 [==============================] - 2704s 319ms/step - loss: 0.3510 - val_loss: 0.2545\n","\n","Epoch 00001: val_loss improved from inf to 0.25452, saving model to ../output/roberta-base-1.h5\n","Epoch 2/3\n","8423/8423 [==============================] - 2688s 319ms/step - loss: 0.2294 - val_loss: 0.2466\n","\n","Epoch 00002: val_loss improved from 0.25452 to 0.24664, saving model to ../output/roberta-base-1.h5\n","Epoch 3/3\n","8423/8423 [==============================] - 2689s 319ms/step - loss: 0.1800 - val_loss: 0.2460\n","\n","Epoch 00003: val_loss improved from 0.24664 to 0.24601, saving model to ../output/roberta-base-1.h5\n","Start predict\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","Convert to train dataset.\n","Buiild model\n"],"name":"stdout"},{"output_type":"stream","text":["Some layers from the model checkpoint at roberta-base were not used when initializing TFRobertaModel: ['lm_head']\n","- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-base.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","Start train\n","Epoch 1/3\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","8423/8423 [==============================] - ETA: 0s - loss: 0.3517WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","8423/8423 [==============================] - 2707s 320ms/step - loss: 0.3516 - val_loss: 0.2615\n","\n","Epoch 00001: val_loss improved from inf to 0.26147, saving model to ../output/roberta-base-2.h5\n","Epoch 2/3\n","8423/8423 [==============================] - 2686s 319ms/step - loss: 0.2296 - val_loss: 0.2577\n","\n","Epoch 00002: val_loss improved from 0.26147 to 0.25767, saving model to ../output/roberta-base-2.h5\n","Epoch 3/3\n","8423/8423 [==============================] - 2684s 319ms/step - loss: 0.1814 - val_loss: 0.2514\n","\n","Epoch 00003: val_loss improved from 0.25767 to 0.25143, saving model to ../output/roberta-base-2.h5\n","Start predict\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BGu_mEyDjGev","executionInfo":{"status":"aborted","timestamp":1616884531952,"user_tz":-540,"elapsed":14212,"user":{"displayName":"西森雅峰","photoUrl":"","userId":"14712724062217715309"}}},"source":["y = train_df[\"is_duplicate\"].values\n","print(\"positive: %.4f\" % np.mean(y))\n","print(\"acc: %.4f\" % accuracy_score(y, oof > 0.5))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SZu7CIvhwdZE","executionInfo":{"status":"aborted","timestamp":1616884531953,"user_tz":-540,"elapsed":14209,"user":{"displayName":"西森雅峰","photoUrl":"","userId":"14712724062217715309"}}},"source":[""],"execution_count":null,"outputs":[]}]}