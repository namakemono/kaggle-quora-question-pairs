{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"train-distilroberta-base.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"widgets":{"application/vnd.jupyter.widget-state+json":{"08c3483b4ec142a0b431771cf9bea9d7":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","state":{"_view_name":"VBoxView","_dom_classes":[],"_model_name":"VBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_28fd26daaeb945aebe8a86240ba708ce","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_8200567e998443d1816f98a00901d74f","IPY_MODEL_d3185b2bab144844afcd16f0be58ed0d"]}},"28fd26daaeb945aebe8a86240ba708ce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8200567e998443d1816f98a00901d74f":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","state":{"_view_name":"LabelView","style":"IPY_MODEL_a081428ee18b4384afa773db401a1d47","_dom_classes":[],"description":"","_model_name":"LabelModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 4.07MB of 4.07MB uploaded (0.00MB deduped)\r","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6e49d284d1e94117a4c741d32acb8c60"}},"d3185b2bab144844afcd16f0be58ed0d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_1a21c27652e94298a18f072ab82c4cc1","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_df2625665fdd4d03805f5e3f33803447"}},"a081428ee18b4384afa773db401a1d47":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"6e49d284d1e94117a4c741d32acb8c60":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1a21c27652e94298a18f072ab82c4cc1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"df2625665fdd4d03805f5e3f33803447":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"555bc06418d8473587cd0a9c7e7bc006":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","state":{"_view_name":"VBoxView","_dom_classes":[],"_model_name":"VBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_1aeea4f2fb114181b774bf2e09c67e17","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_67b5820aa5e2474bb69674173743650b","IPY_MODEL_a7430d0b78984c07976fb3d39f536876"]}},"1aeea4f2fb114181b774bf2e09c67e17":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"67b5820aa5e2474bb69674173743650b":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","state":{"_view_name":"LabelView","style":"IPY_MODEL_67a24e5ae5f341c8aaf7e7f1aac885ef","_dom_classes":[],"description":"","_model_name":"LabelModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 4.07MB of 4.07MB uploaded (0.00MB deduped)\r","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8b810fe6a07143d28399290266774100"}},"a7430d0b78984c07976fb3d39f536876":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_7bb72cd47efd4f028612eb5b6e14f64a","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d0d2ad74f01046eea019aed408dd910c"}},"67a24e5ae5f341c8aaf7e7f1aac885ef":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"8b810fe6a07143d28399290266774100":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7bb72cd47efd4f028612eb5b6e14f64a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"d0d2ad74f01046eea019aed408dd910c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"56827d03744044bdbc4e291e461d3393":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","state":{"_view_name":"VBoxView","_dom_classes":[],"_model_name":"VBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_4adc2b37ceec4241ad8c99182231b308","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_bbc79cc44cab46d396b85e5d519aa96d","IPY_MODEL_c4dcf8159ab0427fb1180c2f55f5b242"]}},"4adc2b37ceec4241ad8c99182231b308":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bbc79cc44cab46d396b85e5d519aa96d":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","state":{"_view_name":"LabelView","style":"IPY_MODEL_4df2fcefa322462b8f0338666f5f5b94","_dom_classes":[],"description":"","_model_name":"LabelModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 4.07MB of 4.07MB uploaded (0.00MB deduped)\r","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_96ebab086058414eb13255e9f9061689"}},"c4dcf8159ab0427fb1180c2f55f5b242":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_e59f5ab9896541528ecfbd00aac7873e","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_55ee01084fd649bb8683aa4b6106e1d2"}},"4df2fcefa322462b8f0338666f5f5b94":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"96ebab086058414eb13255e9f9061689":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e59f5ab9896541528ecfbd00aac7873e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"55ee01084fd649bb8683aa4b6106e1d2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"vQj8Rz1yTMs9"},"source":["## References\n","\n","- https://github.com/huggingface/transformers/blob/5f2a3d721c514cb160c74d2f2df6b729c2f99b2d/examples/text-classification/run_tf_text_classification.py\n","\n","- [Jigsaw TPU: DistilBERT with Huggingface and Keras](https://www.kaggle.com/xhlulu/jigsaw-tpu-distilbert-with-huggingface-and-keras)\n","\n","- https://huggingface.co/transformers/master/training.html"]},{"cell_type":"code","metadata":{"id":"Y-ZZuyEHTMtB","executionInfo":{"status":"ok","timestamp":1616899444684,"user_tz":-540,"elapsed":752,"user":{"displayName":"西森雅峰","photoUrl":"","userId":"14712724062217715309"}}},"source":["import os\n","import sys"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6g508Aqv4w7D","executionInfo":{"status":"ok","timestamp":1616899445082,"user_tz":-540,"elapsed":1143,"user":{"displayName":"西森雅峰","photoUrl":"","userId":"14712724062217715309"}},"outputId":"9c74c064-b9b4-49e2-b67b-4c29820ee9d7"},"source":["if \"google.colab\" in sys.modules:\n","    from google.colab import drive\n","    drive.mount('/content/drive')\n","    %cd /content/drive/MyDrive/kaggle/kaggle-quora-question-pairs/notebook"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/MyDrive/kaggle/kaggle-quora-question-pairs/notebook\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"c30I6d02n7uC","executionInfo":{"status":"ok","timestamp":1616899451957,"user_tz":-540,"elapsed":8014,"user":{"displayName":"西森雅峰","photoUrl":"","userId":"14712724062217715309"}}},"source":["!pip install transformers -q\n","!pip install datasets -q\n","!pip install wandb -q"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"a2QX0XLQhe4A","executionInfo":{"status":"ok","timestamp":1616899454254,"user_tz":-540,"elapsed":10305,"user":{"displayName":"西森雅峰","photoUrl":"","userId":"14712724062217715309"}}},"source":["import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","from sklearn.model_selection import KFold\n","import transformers\n","import datasets\n","from sklearn.metrics import accuracy_score\n","from transformers import (\n","    AutoTokenizer,\n","    TFAutoModelForSequenceClassification,\n",")\n"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"659FQG36ngBH","executionInfo":{"status":"ok","timestamp":1616899455403,"user_tz":-540,"elapsed":11450,"user":{"displayName":"西森雅峰","photoUrl":"","userId":"14712724062217715309"}},"outputId":"e02e3ccc-a120-408b-f2d6-5461189f4206"},"source":["import wandb\n","!wandb login"],"execution_count":5,"outputs":[{"output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnamakemono\u001b[0m (use `wandb login --relogin` to force relogin)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OfusCWHwhhbR","executionInfo":{"status":"ok","timestamp":1616899455403,"user_tz":-540,"elapsed":11446,"user":{"displayName":"西森雅峰","photoUrl":"","userId":"14712724062217715309"}}},"source":["class Config:\n","    def __init__(self):\n","        self.debug = False\n","        self.output_directory = \"../output\"\n","        self.train_filepath = \"../input/quora-question-pairs/train.csv\"\n","        self.test_filepath = \"../input/quora-question-pairs/test.csv\"\n","        self.model_name = \"distilroberta-base\"\n","        self.max_seq_length = 128\n","        self.batch_size = 32\n","        self.epochs = 3\n","        self.num_splits = 3\n","        self.learning_rate=3e-5\n","        self.project_name = \"quora-question-pairs\"\n","        self.name = \"_\".join([\n","            self.model_name,\n","            \"seqlen-%d\" % self.max_seq_length,\n","            \"debug\" if self.debug else \"prod\"\n","        ])\n","        self.weights_filepath_list = [f\"{self.output_directory}/{self.name}-{kfold_index}.h5\" for kfold_index in range(self.num_splits)]\n","        \n","config = Config()"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"kAvpYFUAm3Lu","executionInfo":{"status":"ok","timestamp":1616899455403,"user_tz":-540,"elapsed":11444,"user":{"displayName":"西森雅峰","photoUrl":"","userId":"14712724062217715309"}}},"source":["wandb.config.learning_rate = config.learning_rate\n","wandb.config.batch_size = config.batch_size\n","wandb.config.epochs = config.epochs"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"uxj9BVsEocm1","executionInfo":{"status":"ok","timestamp":1616899455404,"user_tz":-540,"elapsed":11442,"user":{"displayName":"西森雅峰","photoUrl":"","userId":"14712724062217715309"}}},"source":["os.makedirs(config.output_directory, exist_ok=True)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"PRpkzubtnn8r","executionInfo":{"status":"ok","timestamp":1616899456317,"user_tz":-540,"elapsed":12352,"user":{"displayName":"西森雅峰","photoUrl":"","userId":"14712724062217715309"}}},"source":["train_df = pd.read_csv(config.train_filepath)"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"iPXEud95XNY3","executionInfo":{"status":"ok","timestamp":1616899456317,"user_tz":-540,"elapsed":12349,"user":{"displayName":"西森雅峰","photoUrl":"","userId":"14712724062217715309"}}},"source":["def preprocess(df):\n","    df.fillna(\"\", inplace=True)\n","preprocess(train_df)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"1RmzKPQelGSe","executionInfo":{"status":"ok","timestamp":1616899456318,"user_tz":-540,"elapsed":12347,"user":{"displayName":"西森雅峰","photoUrl":"","userId":"14712724062217715309"}}},"source":["if config.debug:\n","    train_df = train_df.sample(300)"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"9cVWJgRk5V-l","executionInfo":{"status":"ok","timestamp":1616899456318,"user_tz":-540,"elapsed":12344,"user":{"displayName":"西森雅峰","photoUrl":"","userId":"14712724062217715309"}},"outputId":"562235f9-8797-4938-8307-bf7866558e8b"},"source":["train_df.head()"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>qid1</th>\n","      <th>qid2</th>\n","      <th>question1</th>\n","      <th>question2</th>\n","      <th>is_duplicate</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>What is the step by step guide to invest in sh...</td>\n","      <td>What is the step by step guide to invest in sh...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n","      <td>What would happen if the Indian government sto...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>5</td>\n","      <td>6</td>\n","      <td>How can I increase the speed of my internet co...</td>\n","      <td>How can Internet speed be increased by hacking...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>7</td>\n","      <td>8</td>\n","      <td>Why am I mentally very lonely? How can I solve...</td>\n","      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>9</td>\n","      <td>10</td>\n","      <td>Which one dissolve in water quikly sugar, salt...</td>\n","      <td>Which fish would survive in salt water?</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   id  qid1  ...                                          question2 is_duplicate\n","0   0     1  ...  What is the step by step guide to invest in sh...            0\n","1   1     3  ...  What would happen if the Indian government sto...            0\n","2   2     5  ...  How can Internet speed be increased by hacking...            0\n","3   3     7  ...  Find the remainder when [math]23^{24}[/math] i...            0\n","4   4     9  ...            Which fish would survive in salt water?            0\n","\n","[5 rows x 6 columns]"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"1j5P_9MdTMtF","executionInfo":{"status":"ok","timestamp":1616899457915,"user_tz":-540,"elapsed":13936,"user":{"displayName":"西森雅峰","photoUrl":"","userId":"14712724062217715309"}}},"source":["tokenizer = AutoTokenizer.from_pretrained(config.model_name, use_fast=True)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"_-VcvYA4imMT","executionInfo":{"status":"ok","timestamp":1616899457917,"user_tz":-540,"elapsed":13935,"user":{"displayName":"西森雅峰","photoUrl":"","userId":"14712724062217715309"}}},"source":["# cf. https://www.kaggle.com/nandanapoorv/entity-recognition-with-tf-keras-and-huggingface\n","# cf. https://www.kaggle.com/cdeotte/tensorflow-roberta-0-705\n","def build_model():\n","    x_input_ids = tf.keras.Input(shape=(config.max_seq_length, ), dtype=tf.int32)\n","    x_attention_mask = tf.keras.Input(shape=(config.max_seq_length, ), dtype=tf.int32)\n","    x_token_type_ids = tf.keras.Input(shape=(config.max_seq_length, ), dtype=tf.int32)\n","    bert_model = transformers.TFAutoModel.from_pretrained(config.model_name)\n","    outputs = bert_model(\n","        input_ids=x_input_ids,\n","        attention_mask=x_attention_mask,\n","        token_type_ids=x_token_type_ids\n","    )\n","    prediction = tf.keras.layers.Dense(1, activation=\"sigmoid\")(outputs.pooler_output)\n","    model = tf.keras.Model(\n","        inputs=[x_input_ids, x_attention_mask, x_token_type_ids],\n","        outputs=[prediction]\n","    )\n","    model.compile(\n","        optimizer=tf.keras.optimizers.Adam(learning_rate=config.learning_rate),\n","        loss=\"binary_crossentropy\",\n","        metrics=[\"acc\"]\n","    )\n","    return model"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"SoEJgCAFimMU","executionInfo":{"status":"ok","timestamp":1616899457918,"user_tz":-540,"elapsed":13933,"user":{"displayName":"西森雅峰","photoUrl":"","userId":"14712724062217715309"}}},"source":["def to_dataset(df):\n","    input_shape = (len(df), config.max_seq_length)\n","    input_ids = np.zeros(input_shape, dtype=np.int32)\n","    attention_mask = np.zeros(input_shape, dtype=np.int32)\n","    token_type_ids = np.zeros(input_shape, dtype=np.int32)\n","    tokens = df.apply(lambda example: tokenizer(\n","        example[\"question1\"],\n","        example[\"question2\"],\n","        truncation=True,\n","        max_length=config.max_seq_length,\n","        padding=\"max_length\"\n","    ), axis=1)\n","    for i, token in enumerate(tokens):\n","        input_ids[i] = token[\"input_ids\"]\n","        attention_mask[i] = token[\"attention_mask\"]\n","        if \"token_type_ids\" in token:\n","            token_type_ids[i] = token[\"token_type_ids\"]\n","    x = (input_ids, attention_mask, token_type_ids)\n","    y = df[\"is_duplicate\"].values\n","    return x, y"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["08c3483b4ec142a0b431771cf9bea9d7","28fd26daaeb945aebe8a86240ba708ce","8200567e998443d1816f98a00901d74f","d3185b2bab144844afcd16f0be58ed0d","a081428ee18b4384afa773db401a1d47","6e49d284d1e94117a4c741d32acb8c60","1a21c27652e94298a18f072ab82c4cc1","df2625665fdd4d03805f5e3f33803447","555bc06418d8473587cd0a9c7e7bc006","1aeea4f2fb114181b774bf2e09c67e17","67b5820aa5e2474bb69674173743650b","a7430d0b78984c07976fb3d39f536876","67a24e5ae5f341c8aaf7e7f1aac885ef","8b810fe6a07143d28399290266774100","7bb72cd47efd4f028612eb5b6e14f64a","d0d2ad74f01046eea019aed408dd910c","56827d03744044bdbc4e291e461d3393","4adc2b37ceec4241ad8c99182231b308","bbc79cc44cab46d396b85e5d519aa96d","c4dcf8159ab0427fb1180c2f55f5b242","4df2fcefa322462b8f0338666f5f5b94","96ebab086058414eb13255e9f9061689","e59f5ab9896541528ecfbd00aac7873e","55ee01084fd649bb8683aa4b6106e1d2"]},"id":"UcThVGKSjGo2","executionInfo":{"status":"ok","timestamp":1616922121332,"user_tz":-540,"elapsed":22677344,"user":{"displayName":"西森雅峰","photoUrl":"","userId":"14712724062217715309"}},"outputId":"157ea5df-565f-4d61-87d6-0ce4fbf47aac"},"source":["kf = KFold(n_splits=config.num_splits, shuffle=True, random_state=777)\n","oof = np.zeros(len(train_df))\n","for kfold_index, (train_index, valid_index) in enumerate(kf.split(train_df)):\n","    print(f\"Create W&B project: {config.name}\")\n","    with wandb.init(project=config.project_name, name=config.name) as wb:\n","        weights_filepath = f\"../output/{config.model_name}-{kfold_index}.h5\"\n","        callbacks = [\n","            tf.keras.callbacks.ModelCheckpoint(\n","                weights_filepath,\n","                monitor=\"val_loss\",\n","                verbose=1,\n","                save_best_only=True,\n","                save_weights_only=True\n","            ),\n","            wandb.keras.WandbCallback()\n","        ]\n","        print(\"Convert to train dataset.\")\n","        x_train, y_train = to_dataset(train_df.iloc[train_index])\n","        x_valid, y_valid = to_dataset(train_df.iloc[valid_index])\n","        print(\"Buiild model\")\n","        model = build_model()\n","        if kfold_index == 0:\n","            print(model.summary())\n","        print(\"Start train\")\n","        model.fit(\n","            x_train, y_train,\n","            validation_data=(x_valid, y_valid),\n","            callbacks=callbacks,\n","            epochs=config.epochs,\n","            batch_size=config.batch_size\n","        )\n","        print(\"Start predict\")\n","        model.load_weights(weights_filepath)\n","        oof[valid_index] = model.predict(x_valid).flatten()"],"execution_count":16,"outputs":[{"output_type":"stream","text":["Create W&B project: distilroberta-base_seqlen-128_prod\n"],"name":"stdout"},{"output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnamakemono\u001b[0m (use `wandb login --relogin` to force relogin)\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["\n","                Tracking run with wandb version 0.10.23<br/>\n","                Syncing run <strong style=\"color:#cdcd00\">distilroberta-base_seqlen-128_prod</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n","                Project page: <a href=\"https://wandb.ai/namakemono/quora-question-pairs\" target=\"_blank\">https://wandb.ai/namakemono/quora-question-pairs</a><br/>\n","                Run page: <a href=\"https://wandb.ai/namakemono/quora-question-pairs/runs/3391sz5o\" target=\"_blank\">https://wandb.ai/namakemono/quora-question-pairs/runs/3391sz5o</a><br/>\n","                Run data is saved locally in <code>/content/drive/My Drive/kaggle/kaggle-quora-question-pairs/notebook/wandb/run-20210328_024418-3391sz5o</code><br/><br/>\n","            "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Convert to train dataset.\n","Buiild model\n"],"name":"stdout"},{"output_type":"stream","text":["Some layers from the model checkpoint at distilroberta-base were not used when initializing TFRobertaModel: ['lm_head']\n","- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFRobertaModel were initialized from the model checkpoint at distilroberta-base.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7fb75a4df1a0>> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7fb75a4df1a0>> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function wrap at 0x7fb785d6ac20> and will run it as-is.\n","Cause: while/else statement not yet supported\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING: AutoGraph could not transform <function wrap at 0x7fb785d6ac20> and will run it as-is.\n","Cause: while/else statement not yet supported\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convertWARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","\n","Model: \"model\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 128)]        0                                            \n","__________________________________________________________________________________________________\n","input_2 (InputLayer)            [(None, 128)]        0                                            \n","__________________________________________________________________________________________________\n","input_3 (InputLayer)            [(None, 128)]        0                                            \n","__________________________________________________________________________________________________\n","tf_roberta_model (TFRobertaMode TFBaseModelOutputWit 82118400    input_1[0][0]                    \n","                                                                 input_2[0][0]                    \n","                                                                 input_3[0][0]                    \n","__________________________________________________________________________________________________\n","dense (Dense)                   (None, 1)            769         tf_roberta_model[0][1]           \n","==================================================================================================\n","Total params: 82,119,169\n","Trainable params: 82,119,169\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","None\n","Start train\n","Epoch 1/3\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","   6/8423 [..............................] - ETA: 34:31 - loss: 0.8245 - acc: 0.3648WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0940s vs `on_train_batch_end` time: 0.1502s). Check your callbacks.\n","8423/8423 [==============================] - ETA: 0s - loss: 0.3705 - acc: 0.8257WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","8423/8423 [==============================] - 2375s 281ms/step - loss: 0.3705 - acc: 0.8257 - val_loss: 0.2688 - val_acc: 0.8845\n","\n","Epoch 00001: val_loss improved from inf to 0.26881, saving model to ../output/distilroberta-base-0.h5\n"],"name":"stdout"},{"output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Can't save model, h5py returned error: \n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 2/3\n","8423/8423 [==============================] - 2364s 281ms/step - loss: 0.2386 - acc: 0.8981 - val_loss: 0.2572 - val_acc: 0.8891\n","\n","Epoch 00002: val_loss improved from 0.26881 to 0.25724, saving model to ../output/distilroberta-base-0.h5\n","Epoch 3/3\n","8423/8423 [==============================] - 2363s 281ms/step - loss: 0.1851 - acc: 0.9256 - val_loss: 0.2640 - val_acc: 0.8990\n","\n","Epoch 00003: val_loss did not improve from 0.25724\n","Start predict\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<br/>Waiting for W&B process to finish, PID 1851<br/>Program ended successfully."],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"08c3483b4ec142a0b431771cf9bea9d7","version_minor":0,"version_major":2},"text/plain":["VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["Find user logs for this run at: <code>/content/drive/My Drive/kaggle/kaggle-quora-question-pairs/notebook/wandb/run-20210328_024418-3391sz5o/logs/debug.log</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["Find internal logs for this run at: <code>/content/drive/My Drive/kaggle/kaggle-quora-question-pairs/notebook/wandb/run-20210328_024418-3391sz5o/logs/debug-internal.log</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<h3>Run summary:</h3><br/><style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n","    </style><table class=\"wandb\">\n","<tr><td>epoch</td><td>2</td></tr><tr><td>loss</td><td>0.1874</td></tr><tr><td>acc</td><td>0.92413</td></tr><tr><td>val_loss</td><td>0.26401</td></tr><tr><td>val_acc</td><td>0.89899</td></tr><tr><td>_runtime</td><td>7233</td></tr><tr><td>_timestamp</td><td>1616906691</td></tr><tr><td>_step</td><td>2</td></tr><tr><td>best_val_loss</td><td>0.25724</td></tr><tr><td>best_epoch</td><td>1</td></tr></table>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<h3>Run history:</h3><br/><style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n","    </style><table class=\"wandb\">\n","<tr><td>epoch</td><td>▁▅█</td></tr><tr><td>loss</td><td>█▄▁</td></tr><tr><td>acc</td><td>▁▅█</td></tr><tr><td>val_loss</td><td>█▁▅</td></tr><tr><td>val_acc</td><td>▁▃█</td></tr><tr><td>_runtime</td><td>▁▅█</td></tr><tr><td>_timestamp</td><td>▁▅█</td></tr><tr><td>_step</td><td>▁▅█</td></tr></table><br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["\n","                    <br/>Synced <strong style=\"color:#cdcd00\">distilroberta-base_seqlen-128_prod</strong>: <a href=\"https://wandb.ai/namakemono/quora-question-pairs/runs/3391sz5o\" target=\"_blank\">https://wandb.ai/namakemono/quora-question-pairs/runs/3391sz5o</a><br/>\n","                "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Create W&B project: distilroberta-base_seqlen-128_prod\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["\n","                Tracking run with wandb version 0.10.23<br/>\n","                Syncing run <strong style=\"color:#cdcd00\">distilroberta-base_seqlen-128_prod</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n","                Project page: <a href=\"https://wandb.ai/namakemono/quora-question-pairs\" target=\"_blank\">https://wandb.ai/namakemono/quora-question-pairs</a><br/>\n","                Run page: <a href=\"https://wandb.ai/namakemono/quora-question-pairs/runs/eacbcax0\" target=\"_blank\">https://wandb.ai/namakemono/quora-question-pairs/runs/eacbcax0</a><br/>\n","                Run data is saved locally in <code>/content/drive/My Drive/kaggle/kaggle-quora-question-pairs/notebook/wandb/run-20210328_045032-eacbcax0</code><br/><br/>\n","            "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Convert to train dataset.\n","Buiild model\n"],"name":"stdout"},{"output_type":"stream","text":["Some layers from the model checkpoint at distilroberta-base were not used when initializing TFRobertaModel: ['lm_head']\n","- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFRobertaModel were initialized from the model checkpoint at distilroberta-base.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","Start train\n","Epoch 1/3\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","   6/8423 [..............................] - ETA: 34:23 - loss: 0.6810 - acc: 0.6471WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0943s vs `on_train_batch_end` time: 0.1516s). Check your callbacks.\n","8423/8423 [==============================] - ETA: 0s - loss: 0.3644 - acc: 0.8302WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","8423/8423 [==============================] - 2372s 281ms/step - loss: 0.3644 - acc: 0.8302 - val_loss: 0.2681 - val_acc: 0.8836\n","\n","Epoch 00001: val_loss improved from inf to 0.26811, saving model to ../output/distilroberta-base-1.h5\n"],"name":"stdout"},{"output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Can't save model, h5py returned error: \n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 2/3\n","8423/8423 [==============================] - 2366s 281ms/step - loss: 0.2365 - acc: 0.9002 - val_loss: 0.2703 - val_acc: 0.8942\n","\n","Epoch 00002: val_loss did not improve from 0.26811\n","Epoch 3/3\n","8423/8423 [==============================] - 2366s 281ms/step - loss: 0.1840 - acc: 0.9254 - val_loss: 0.2556 - val_acc: 0.9017\n","\n","Epoch 00003: val_loss improved from 0.26811 to 0.25563, saving model to ../output/distilroberta-base-1.h5\n","Start predict\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<br/>Waiting for W&B process to finish, PID 2428<br/>Program ended successfully."],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"555bc06418d8473587cd0a9c7e7bc006","version_minor":0,"version_major":2},"text/plain":["VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["Find user logs for this run at: <code>/content/drive/My Drive/kaggle/kaggle-quora-question-pairs/notebook/wandb/run-20210328_045032-eacbcax0/logs/debug.log</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["Find internal logs for this run at: <code>/content/drive/My Drive/kaggle/kaggle-quora-question-pairs/notebook/wandb/run-20210328_045032-eacbcax0/logs/debug-internal.log</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<h3>Run summary:</h3><br/><style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n","    </style><table class=\"wandb\">\n","<tr><td>epoch</td><td>2</td></tr><tr><td>loss</td><td>0.18653</td></tr><tr><td>acc</td><td>0.9241</td></tr><tr><td>val_loss</td><td>0.25563</td></tr><tr><td>val_acc</td><td>0.90169</td></tr><tr><td>_runtime</td><td>7197</td></tr><tr><td>_timestamp</td><td>1616914230</td></tr><tr><td>_step</td><td>2</td></tr><tr><td>best_val_loss</td><td>0.25563</td></tr><tr><td>best_epoch</td><td>2</td></tr></table>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<h3>Run history:</h3><br/><style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n","    </style><table class=\"wandb\">\n","<tr><td>epoch</td><td>▁▅█</td></tr><tr><td>loss</td><td>█▄▁</td></tr><tr><td>acc</td><td>▁▆█</td></tr><tr><td>val_loss</td><td>▇█▁</td></tr><tr><td>val_acc</td><td>▁▅█</td></tr><tr><td>_runtime</td><td>▁▄█</td></tr><tr><td>_timestamp</td><td>▁▄█</td></tr><tr><td>_step</td><td>▁▅█</td></tr></table><br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["\n","                    <br/>Synced <strong style=\"color:#cdcd00\">distilroberta-base_seqlen-128_prod</strong>: <a href=\"https://wandb.ai/namakemono/quora-question-pairs/runs/eacbcax0\" target=\"_blank\">https://wandb.ai/namakemono/quora-question-pairs/runs/eacbcax0</a><br/>\n","                "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Create W&B project: distilroberta-base_seqlen-128_prod\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["\n","                Tracking run with wandb version 0.10.23<br/>\n","                Syncing run <strong style=\"color:#cdcd00\">distilroberta-base_seqlen-128_prod</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n","                Project page: <a href=\"https://wandb.ai/namakemono/quora-question-pairs\" target=\"_blank\">https://wandb.ai/namakemono/quora-question-pairs</a><br/>\n","                Run page: <a href=\"https://wandb.ai/namakemono/quora-question-pairs/runs/gx0v6a3b\" target=\"_blank\">https://wandb.ai/namakemono/quora-question-pairs/runs/gx0v6a3b</a><br/>\n","                Run data is saved locally in <code>/content/drive/My Drive/kaggle/kaggle-quora-question-pairs/notebook/wandb/run-20210328_065605-gx0v6a3b</code><br/><br/>\n","            "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Convert to train dataset.\n","Buiild model\n"],"name":"stdout"},{"output_type":"stream","text":["Some layers from the model checkpoint at distilroberta-base were not used when initializing TFRobertaModel: ['lm_head']\n","- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFRobertaModel were initialized from the model checkpoint at distilroberta-base.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","Start train\n","Epoch 1/3\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","   6/8423 [..............................] - ETA: 34:25 - loss: 0.6875 - acc: 0.5787WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0942s vs `on_train_batch_end` time: 0.1519s). Check your callbacks.\n","8423/8423 [==============================] - ETA: 0s - loss: 0.3675 - acc: 0.8281WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","8423/8423 [==============================] - 2377s 281ms/step - loss: 0.3675 - acc: 0.8281 - val_loss: 0.2632 - val_acc: 0.8884\n","\n","Epoch 00001: val_loss improved from inf to 0.26322, saving model to ../output/distilroberta-base-2.h5\n"],"name":"stdout"},{"output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Can't save model, h5py returned error: \n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 2/3\n","8423/8423 [==============================] - 2373s 282ms/step - loss: 0.2385 - acc: 0.8990 - val_loss: 0.2585 - val_acc: 0.8939\n","\n","Epoch 00002: val_loss improved from 0.26322 to 0.25852, saving model to ../output/distilroberta-base-2.h5\n","Epoch 3/3\n","8423/8423 [==============================] - 2372s 282ms/step - loss: 0.1853 - acc: 0.9245 - val_loss: 0.2498 - val_acc: 0.8996\n","\n","Epoch 00003: val_loss improved from 0.25852 to 0.24979, saving model to ../output/distilroberta-base-2.h5\n","Start predict\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<br/>Waiting for W&B process to finish, PID 3028<br/>Program ended successfully."],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"56827d03744044bdbc4e291e461d3393","version_minor":0,"version_major":2},"text/plain":["VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["Find user logs for this run at: <code>/content/drive/My Drive/kaggle/kaggle-quora-question-pairs/notebook/wandb/run-20210328_065605-gx0v6a3b/logs/debug.log</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["Find internal logs for this run at: <code>/content/drive/My Drive/kaggle/kaggle-quora-question-pairs/notebook/wandb/run-20210328_065605-gx0v6a3b/logs/debug-internal.log</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<h3>Run summary:</h3><br/><style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n","    </style><table class=\"wandb\">\n","<tr><td>epoch</td><td>2</td></tr><tr><td>loss</td><td>0.18728</td></tr><tr><td>acc</td><td>0.92368</td></tr><tr><td>val_loss</td><td>0.24979</td></tr><tr><td>val_acc</td><td>0.89956</td></tr><tr><td>_runtime</td><td>7219</td></tr><tr><td>_timestamp</td><td>1616921785</td></tr><tr><td>_step</td><td>2</td></tr><tr><td>best_val_loss</td><td>0.24979</td></tr><tr><td>best_epoch</td><td>2</td></tr></table>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<h3>Run history:</h3><br/><style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n","    </style><table class=\"wandb\">\n","<tr><td>epoch</td><td>▁▅█</td></tr><tr><td>loss</td><td>█▄▁</td></tr><tr><td>acc</td><td>▁▆█</td></tr><tr><td>val_loss</td><td>█▆▁</td></tr><tr><td>val_acc</td><td>▁▄█</td></tr><tr><td>_runtime</td><td>▁▅█</td></tr><tr><td>_timestamp</td><td>▁▅█</td></tr><tr><td>_step</td><td>▁▅█</td></tr></table><br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["\n","                    <br/>Synced <strong style=\"color:#cdcd00\">distilroberta-base_seqlen-128_prod</strong>: <a href=\"https://wandb.ai/namakemono/quora-question-pairs/runs/gx0v6a3b\" target=\"_blank\">https://wandb.ai/namakemono/quora-question-pairs/runs/gx0v6a3b</a><br/>\n","                "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"BGu_mEyDjGev","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616922121338,"user_tz":-540,"elapsed":22677345,"user":{"displayName":"西森雅峰","photoUrl":"","userId":"14712724062217715309"}},"outputId":"439b65a0-0053-45c9-e47c-25a398f1fb5e"},"source":["y = train_df[\"is_duplicate\"].values\n","print(\"positive: %.4f\" % np.mean(y))\n","print(\"acc: %.4f\" % accuracy_score(y, oof > 0.5))"],"execution_count":17,"outputs":[{"output_type":"stream","text":["positive: 0.3692\n","acc: 0.8968\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SZu7CIvhwdZE","executionInfo":{"status":"ok","timestamp":1616922121340,"user_tz":-540,"elapsed":22677343,"user":{"displayName":"西森雅峰","photoUrl":"","userId":"14712724062217715309"}}},"source":[""],"execution_count":17,"outputs":[]}]}